{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbf6f10",
   "metadata": {},
   "source": [
    "# Engineering Practice Tutorial #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e8703",
   "metadata": {},
   "source": [
    "> Welecome to Explainable Factual Reasoning Lab (a.k.a xfact lab). In this tutorial, we are going to cover management strategies in the lab\n",
    "\n",
    "> Contents\n",
    "    > 1. Components of paper\n",
    "    > 2. Reproducible Research \n",
    "    > 3. GPU management\n",
    "    > 4. Data management\n",
    "    > 5. Experiments management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69325b",
   "metadata": {},
   "source": [
    "## 1. Components of paper\n",
    "Paper consists of three components \n",
    "- __Code__\n",
    "    - github links\n",
    "- __Table & Graph__\n",
    "    - research results\n",
    "- __Data__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa0008",
   "metadata": {},
   "source": [
    "## 2. Reproducible Research \n",
    "In user's point of view, they want to utilize or reproduce the results on the paper. Therefore, need to manage packages, code, and data.\n",
    "- __Managing pacakge dependecies__\n",
    "    - pip package\n",
    "        - managed by 'requirements.txt' file\n",
    "        - pip freeze -r\n",
    "    - poetry package \n",
    "    - docker image\n",
    "- __Managing code__\n",
    "    - github\n",
    "        - snapshots of code\n",
    "- __Managing data__\n",
    "    - Publicly\n",
    "        - Cloud services (S3)\n",
    "    - Privately (Locally)\n",
    "        - NFS\n",
    "        - MINIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10efcfa0",
   "metadata": {},
   "source": [
    "## 3. GPU management \n",
    "`SLURM` is used for GPU clustering and allocation\n",
    "* `SLURM`\n",
    "    - open source, fault-tolerant, and highly scalable cluster management and job scheduling system for large and small Linux clusters [SLURM](https://slurm.schedmd.com/overview.html)\n",
    "    \n",
    "    - Features\n",
    "\t\t- Able to use bash script to initiate training on multi-GPU clusters \n",
    "\t\t- Able to assigning Priorities (using multilevel queue)\n",
    "\t\t\t- High\n",
    "\t\t\t- Standard\n",
    "\t\t\t- Low\n",
    "\t\t\t- Intermediate \n",
    "\t\t\t\t- Debugging or Checking whether scripts are running appropriately\n",
    "\n",
    "    - e.g.)\n",
    "        - bash commands \n",
    "            -> using only local destop GPUs\n",
    "        - qsub commands \n",
    "            -> sending scripts to server and running on GPU clusters (using server and local desktop GPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19fb9a",
   "metadata": {},
   "source": [
    "## 4. Data management\n",
    "\n",
    "- NFS (Network File System)\n",
    "    - `/data`, `/home` directories are NFS \t\n",
    "    - Locations\n",
    "        - `/data` \n",
    "            - large files w/o backup\n",
    "        - `/home`\n",
    "            - small files w/ backup \n",
    "            - backup on hourly basis\n",
    "            - user accounts are located under /home directory. Therefore, it would be a good practice to save extremely large models OR frequently used data under `/data`\n",
    "- Local\n",
    "    - `/scratch`\n",
    "        - for high frequency files (files frequently used such as caches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb3ba8",
   "metadata": {},
   "source": [
    "## 5. Experiments management\n",
    "- __Parameters Management__\n",
    "\t- Framework (easiest, fastest)\n",
    "\t\t- comet\n",
    "\t\t- wandb\n",
    "\t\t- tensorboard\n",
    "\t- Files\n",
    "\t\t- JSON\n",
    "        - YAML \n",
    "\t- CMD output stdout or file \n",
    "\t\t- bash -v\n",
    "\t\t\t- verbose : print each command to stdout before executing it\n",
    "\t\t- bash -x \n",
    "\t\t\t- xtrace : Similar to -v, but expands commands\n",
    "\n",
    "\n",
    "- __Model Management__\n",
    "    - One folder per experiemnt\n",
    "        -  contains all necessary files related to the experiment : tokenizer, parameters, models, and etc. \n",
    "    - Every experiments should have own unique identifier\n",
    "        - e.g.) `{Path}/experiment/{github code tag or hash ID}/{slurm_id}/trial_1`\n",
    "\n",
    "\n",
    "- __Code Management__\n",
    "    - Use git tag feature (or hash ID) as identifier for training experiment\n",
    "        - e.g.) `{Path}/experiment/{github code tag or hash ID}/{slurm_id}/trial_2`\n",
    "    - Manage remote repository on individual laptops\n",
    "        - Hard to track down corressponding code to each experiment when there are some direct modifications on the server.\n",
    "    - Git pull codes from remote repository on the server\n",
    "        - Easier to find corresponding code to each experiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_transformers",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
